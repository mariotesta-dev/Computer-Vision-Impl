{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet implementation"
      ],
      "metadata": {
        "id": "EDfrzOYOibqV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PdCC4NKbiZnR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, in_channels=3, classes=10): #3 input channels because we use RGB, and we'll have 1000 output classes (this is given by the dataset we're using)\n",
        "    super().__init__()\n",
        "    # Initialize each layer\n",
        "    self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "    self.c2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
        "    self.c3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "    self.c4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "    self.c5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(in_features=6*6*256, out_features=4096)\n",
        "    self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "    self.fc3 = nn.Linear(in_features=4096, out_features=classes)\n",
        "    self.norm = nn.LocalResponseNorm(k=2, size=5, alpha=1e-4, beta=0.75)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    # Initialize weights\n",
        "    self.weight_init()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.maxpool(self.norm(self.relu(self.c1(x))))\n",
        "      x = self.maxpool(self.norm(self.relu(self.c2(x))))\n",
        "      x = self.relu(self.c3(x))\n",
        "      x = self.relu(self.c4(x))\n",
        "      x = self.maxpool(self.relu(self.c5(x)))\n",
        "      x = torch.flatten(x,1)\n",
        "      x = self.relu(self.fc1(self.dropout(x)))\n",
        "      x = self.relu(self.fc2(self.dropout(x)))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "  def weight_init(self):\n",
        "    bias = [1,3,4,5,6,7]\n",
        "    for i, layer in enumerate(self.modules()):\n",
        "      if layer is nn.Conv2d or layer is nn.Linear:\n",
        "        nn.init.normal_(mean=0, std=0.01)\n",
        "        if i in bias:\n",
        "          nn.init.constant_(layer, 1)\n",
        "        else:\n",
        "          nn.init.constant_(layer, 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "s27KQ_iDlG-w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2Xs8zZoSHV4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 train dataset\n",
        "data_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((224,224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "cifar10_train_dataset = torchvision.datasets.CIFAR10(root='./data', download=True, train=True, transform=data_transforms)\n",
        "train_dataloader = torch.utils.data.DataLoader(cifar10_train_dataset,\n",
        "                                         batch_size = 32,\n",
        "                                         shuffle=True)\n",
        "\n",
        "# Load AlexNet\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = VGG16_A().to(device)\n",
        "model.train()\n",
        "\n",
        "# Define Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "epoch_nums = 2 # small just for working demonstration\n",
        "# Train the network\n",
        "for epoch in range(epoch_nums):\n",
        "\n",
        "  current_loss = 0.0\n",
        "  for i, data in tqdm(enumerate(train_dataloader, start = 0), unit=\"batch\", total=len(train_dataloader), desc=f\"Epoch {epoch}\"):\n",
        "    # get inputs -> data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass + backward + optimize\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # compute statistics\n",
        "    current_loss += loss.item()\n",
        "    if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print(f'current loss: {current_loss / 100:.3f}')\n",
        "            current_loss = 0.0\n",
        "\n",
        "print(\"Training done! Saving trained model to: './trained_model.pth'\")\n",
        "torch.save(model.state_dict(), './trained_model.pth')\n",
        "print(\"Saved.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdpRvUibsUcI",
        "outputId": "4c7d1a7b-5654-4e6b-8c34-54c7fc7191e3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   6%|▋         | 101/1563 [00:10<02:58,  8.19batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 2.303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  13%|█▎        | 201/1563 [00:21<02:24,  9.43batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 2.300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  19%|█▉        | 301/1563 [00:32<02:11,  9.58batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 2.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  26%|██▌       | 401/1563 [00:43<02:00,  9.67batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 2.031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  32%|███▏      | 501/1563 [00:54<01:50,  9.63batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  38%|███▊      | 601/1563 [01:05<01:39,  9.67batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  45%|████▍     | 701/1563 [01:16<01:40,  8.59batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  51%|█████     | 801/1563 [01:26<01:33,  8.15batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  58%|█████▊    | 901/1563 [01:37<01:11,  9.26batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  64%|██████▍   | 1001/1563 [01:48<00:59,  9.41batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  70%|███████   | 1101/1563 [01:59<00:49,  9.41batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  77%|███████▋  | 1201/1563 [02:10<00:37,  9.60batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  83%|████████▎ | 1301/1563 [02:21<00:27,  9.59batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  90%|████████▉ | 1401/1563 [02:32<00:19,  8.33batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  96%|█████████▌| 1501/1563 [02:43<00:06,  9.57batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1563/1563 [02:49<00:00,  9.20batch/s]\n",
            "Epoch 1:   6%|▋         | 101/1563 [00:11<02:35,  9.40batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  13%|█▎        | 201/1563 [00:22<02:44,  8.27batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  19%|█▉        | 301/1563 [00:33<02:31,  8.33batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  26%|██▌       | 401/1563 [00:43<02:05,  9.22batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  32%|███▏      | 501/1563 [00:54<01:50,  9.64batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  38%|███▊      | 601/1563 [01:05<01:42,  9.38batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  45%|████▍     | 701/1563 [01:16<01:29,  9.59batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  51%|█████     | 801/1563 [01:27<01:20,  9.48batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  58%|█████▊    | 901/1563 [01:38<01:21,  8.08batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  64%|██████▍   | 1001/1563 [01:49<00:59,  9.39batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  70%|███████   | 1101/1563 [02:00<00:49,  9.41batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 1.013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  77%|███████▋  | 1201/1563 [02:11<00:38,  9.51batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 0.996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  83%|████████▎ | 1301/1563 [02:22<00:28,  9.34batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 0.970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  90%|████████▉ | 1401/1563 [02:33<00:17,  9.31batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 0.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  96%|█████████▌| 1501/1563 [02:44<00:07,  8.86batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current loss: 0.971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1563/1563 [02:50<00:00,  9.14batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done! Saving trained model to: './trained_model'\n",
            "Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "H3wHQpyzHSN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 test dataset\n",
        "data_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((227,227)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "cifar10_test_dataset = torchvision.datasets.CIFAR10(root='./data', download=True, train=False, transform=data_transforms)\n",
        "test_dataloader = torch.utils.data.DataLoader(cifar10_test_dataset,\n",
        "                                         batch_size = 32,\n",
        "                                         shuffle=True)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = AlexNet().to(device)\n",
        "model.load_state_dict(torch.load(\"./trained_model.pth\"))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in tqdm(test_dataloader):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'\\nAccuracy of AlexNet on CIFAR10: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY4F8RwQFVLz",
        "outputId": "7ae22c3e-417a-4daa-d2c9-660622e6f383"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:24<00:00, 12.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy of AlexNet on CIFAR10: 68 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}